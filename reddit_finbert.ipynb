{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wekh_742k3K5"
      },
      "outputs": [],
      "source": [
        "! pip install transformers\n",
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8arwsc8ASywQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "# from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "BNiFNePakuUS",
        "outputId": "dac84822-cd27-42db-d143-f54fb688d832"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "osWO0KAHSwVE",
        "outputId": "aa67ef19-7de0-4cfd-f233-e5abe2efa3e7"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import Row, SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "75gEPv-fS54u"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load models\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nggPaVLZOB4I"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ALzGOSogk6AX"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data/2023-02-10/reddit.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhhgxdWK0YFR",
        "outputId": "93f81e56-3a0d-4a09-be66-59549f4e1238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6464 entries, 0 to 6463\n",
            "Data columns (total 97 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   subreddit                      6464 non-null   object \n",
            " 1   selftext                       3633 non-null   object \n",
            " 2   author_fullname                6407 non-null   object \n",
            " 3   gilded                         6464 non-null   int64  \n",
            " 4   title                          6464 non-null   object \n",
            " 5   link_flair_richtext            6464 non-null   object \n",
            " 6   subreddit_name_prefixed        6464 non-null   object \n",
            " 7   hidden                         6464 non-null   bool   \n",
            " 8   pwls                           6464 non-null   int64  \n",
            " 9   link_flair_css_class           4540 non-null   object \n",
            " 10  thumbnail_height               2958 non-null   float64\n",
            " 11  top_awarded_type               0 non-null      float64\n",
            " 12  hide_score                     6464 non-null   bool   \n",
            " 13  quarantine                     6464 non-null   bool   \n",
            " 14  link_flair_text_color          6450 non-null   object \n",
            " 15  upvote_ratio                   6464 non-null   float64\n",
            " 16  author_flair_background_color  78 non-null     object \n",
            " 17  subreddit_type                 6464 non-null   object \n",
            " 18  total_awards_received          6464 non-null   int64  \n",
            " 19  media_embed                    6464 non-null   object \n",
            " 20  thumbnail_width                2958 non-null   float64\n",
            " 21  author_flair_template_id       80 non-null     object \n",
            " 22  is_original_content            6464 non-null   bool   \n",
            " 23  secure_media                   89 non-null     object \n",
            " 24  is_reddit_media_domain         6464 non-null   bool   \n",
            " 25  is_meta                        6464 non-null   bool   \n",
            " 26  category                       0 non-null      float64\n",
            " 27  secure_media_embed             6464 non-null   object \n",
            " 28  link_flair_text                5269 non-null   object \n",
            " 29  score                          6464 non-null   int64  \n",
            " 30  is_created_from_ads_ui         6464 non-null   bool   \n",
            " 31  author_premium                 6407 non-null   object \n",
            " 32  thumbnail                      6464 non-null   object \n",
            " 33  edited                         6464 non-null   bool   \n",
            " 34  author_flair_css_class         14 non-null     object \n",
            " 35  author_flair_richtext          6407 non-null   object \n",
            " 36  gildings                       6464 non-null   object \n",
            " 37  content_categories             0 non-null      float64\n",
            " 38  is_self                        6464 non-null   bool   \n",
            " 39  link_flair_type                6464 non-null   object \n",
            " 40  wls                            6464 non-null   int64  \n",
            " 41  removed_by_category            3256 non-null   object \n",
            " 42  author_flair_type              6407 non-null   object \n",
            " 43  domain                         6407 non-null   object \n",
            " 44  allow_live_comments            6464 non-null   bool   \n",
            " 45  suggested_sort                 4928 non-null   object \n",
            " 46  url_overridden_by_dest         2835 non-null   object \n",
            " 47  view_count                     0 non-null      float64\n",
            " 48  archived                       6464 non-null   bool   \n",
            " 49  no_follow                      6464 non-null   bool   \n",
            " 50  is_crosspostable               6464 non-null   bool   \n",
            " 51  pinned                         6464 non-null   bool   \n",
            " 52  over_18                        6464 non-null   bool   \n",
            " 53  all_awardings                  6464 non-null   object \n",
            " 54  awarders                       6464 non-null   object \n",
            " 55  media_only                     6464 non-null   bool   \n",
            " 56  link_flair_template_id         5192 non-null   object \n",
            " 57  can_gild                       6464 non-null   bool   \n",
            " 58  spoiler                        6464 non-null   bool   \n",
            " 59  locked                         6464 non-null   bool   \n",
            " 60  author_flair_text              161 non-null    object \n",
            " 61  treatment_tags                 6464 non-null   object \n",
            " 62  removed_by                     0 non-null      float64\n",
            " 63  distinguished                  0 non-null      float64\n",
            " 64  subreddit_id                   6464 non-null   object \n",
            " 65  link_flair_background_color    5163 non-null   object \n",
            " 66  id                             6464 non-null   object \n",
            " 67  is_robot_indexable             6464 non-null   bool   \n",
            " 68  author                         6464 non-null   object \n",
            " 69  discussion_type                7 non-null      object \n",
            " 70  num_comments                   6464 non-null   int64  \n",
            " 71  send_replies                   6464 non-null   bool   \n",
            " 72  whitelist_status               6464 non-null   object \n",
            " 73  contest_mode                   6464 non-null   bool   \n",
            " 74  author_patreon_flair           6407 non-null   object \n",
            " 75  author_flair_text_color        223 non-null    object \n",
            " 76  permalink                      6464 non-null   object \n",
            " 77  parent_whitelist_status        6464 non-null   object \n",
            " 78  stickied                       6464 non-null   bool   \n",
            " 79  url                            6407 non-null   object \n",
            " 80  subreddit_subscribers          6464 non-null   int64  \n",
            " 81  created_utc                    6464 non-null   int64  \n",
            " 82  num_crossposts                 6464 non-null   int64  \n",
            " 83  media                          89 non-null     object \n",
            " 84  is_video                       6464 non-null   bool   \n",
            " 85  retrieved_utc                  6464 non-null   int64  \n",
            " 86  updated_utc                    6464 non-null   int64  \n",
            " 87  utc_datetime_str               6464 non-null   object \n",
            " 88  media_metadata                 283 non-null    object \n",
            " 89  post_hint                      2979 non-null   object \n",
            " 90  preview                        2979 non-null   object \n",
            " 91  is_gallery                     256 non-null    object \n",
            " 92  gallery_data                   130 non-null    object \n",
            " 93  crosspost_parent_list          28 non-null     object \n",
            " 94  crosspost_parent               28 non-null     object \n",
            " 95  author_cakeday                 17 non-null     object \n",
            " 96  poll_data                      0 non-null      float64\n",
            "dtypes: bool(24), float64(10), int64(11), object(52)\n",
            "memory usage: 3.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Cegwh0G8rxuC",
        "outputId": "76687b9f-65b3-4c1c-ffda-0499a5c430d1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d89dcf03-f203-46f8-b4af-a1dc7b99fa53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Wycoff accumulation?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>TIENES MIEDO DE QUE BTC BAJE? ARE YOU AFRAID O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Que les parece esta grafica?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Trading en la apertura del mercado el viernes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>any good stocks for a first time investor?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d89dcf03-f203-46f8-b4af-a1dc7b99fa53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d89dcf03-f203-46f8-b4af-a1dc7b99fa53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d89dcf03-f203-46f8-b4af-a1dc7b99fa53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                title\n",
              "9                                Wycoff accumulation?\n",
              "16  TIENES MIEDO DE QUE BTC BAJE? ARE YOU AFRAID O...\n",
              "18                       Que les parece esta grafica?\n",
              "23      Trading en la apertura del mercado el viernes\n",
              "24         any good stocks for a first time investor?"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['selftext']==\"[removed]\"][['title']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OaM_ABNwrvjP"
      },
      "outputs": [],
      "source": [
        "na_cond = (df['selftext'].isna()) | (df['title'].isna())\n",
        "df = df[~na_cond]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "5PKHgHn2rp6V"
      },
      "outputs": [],
      "source": [
        "df_sample = df.iloc[:20].reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "XVzsGCAXlwfJ",
        "outputId": "5694256b-527e-4c06-86ca-5ce47df8ee3b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_sample' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_sample\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mdata/toy.csv\u001b[39m\u001b[39m\"\u001b[39m,index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_sample' is not defined"
          ]
        }
      ],
      "source": [
        "df_sample.to_csv(\"data/toy.csv\",index=False)\n",
        "# df_sample = pd.read_csv(\"/content/drive/MyDrive/MSDS697/toy.csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o-4IXsy1m8qJ"
      },
      "source": [
        "# Preprocessing on text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sample = pd.read_csv(\"data/toy.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "WytE1DVIlxgX",
        "outputId": "866c55b1-baef-429d-f761-58d144d270ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'500k to invest in the most R way!\\nI got 500k in various 401ks, Roths, and Brokerage accounts. Hoping to get to $1mil in 5 years. What’s the most smooth brain way to invest to get there, based on those investment limitations?'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sample[\"fulltext\"] = df_sample['title'] + \"\\n\" + df_sample['selftext']\n",
        "df_sample[\"fulltext\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['fulltext'] = df['title'] + \"\\n\" + df['selftext']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "lines = [\"AAPL and MSFT are doing well\", \"App development\", \"Invest in AAPL\"]\n",
        "df_lines = pd.DataFrame({\"lines\":lines})\n",
        "tickers = [\"AAPL\", \"MSFT\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     True\n",
              "1    False\n",
              "2     True\n",
              "Name: lines, dtype: bool"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_lines['lines'].str.contains(\"|\".join(stickers), case=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2995"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tickers = pd.read_csv(\"data/Russell 3000 - Google Spreadsheet - Sheet 1.csv\")['Ticker'].to_list()\n",
        "len(tickers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1       True\n",
              "2       True\n",
              "4       True\n",
              "5       True\n",
              "6       True\n",
              "        ... \n",
              "6459    True\n",
              "6460    True\n",
              "6461    True\n",
              "6462    True\n",
              "6463    True\n",
              "Name: fulltext, Length: 3633, dtype: bool"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['fulltext'].str.contains(\"|\".join(tickers), case=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenization Test\n",
        "\n",
        "Test on tokenizer limit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiLdNdfSnsCR",
        "outputId": "dc7fd06b-d557-414b-9101-9cc1b6acbadf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "61\n",
            "3024\n",
            "284\n",
            "75\n",
            "48\n",
            "11\n",
            "44\n",
            "2673\n",
            "25\n",
            "62\n",
            "14\n",
            "2688\n",
            "19\n",
            "14\n",
            "43\n",
            "34\n",
            "11\n",
            "14\n",
            "67\n",
            "85\n"
          ]
        }
      ],
      "source": [
        "for text in df_sample['fulltext']:\n",
        "  token_ids = tokenizer.encode(text)\n",
        "  print(len(token_ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LtL8N3vq5lD"
      },
      "source": [
        "Will occasionally come across posts longer than 500 tokens.\n",
        "\n",
        "How to deal with it now: divide by new line and truncate by 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP2ZiVavoRjq"
      },
      "outputs": [],
      "source": [
        "# estimate for all\n",
        "tokens_len = []\n",
        "for fulltext in df['fulltext']:\n",
        "  paragraphs = fulltext.split(\"\\n\")\n",
        "  for p in paragraphs:\n",
        "    token_ids = tokenizer.encode(p)\n",
        "    tokens_len.append(len(token_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "DJ7dIf8ZsXiS",
        "outputId": "aef3f586-0c07-469c-dd84-eb15c5a5e752"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokens_len = np.array(tokens_len)\n",
        "plt.hist(tokens_len);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIdfrPU4tEL0",
        "outputId": "508799d9-d7c8-4904-c105-eb49f70f4fe2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.666360012266176e-05"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(tokens_len > 512).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nV8Z_NCtqMH"
      },
      "source": [
        "After truncating with newline, most paragraphs are less than 512 tokens"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fw4nwFEmwRad"
      },
      "source": [
        "# Predict One (Long) Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "wydd2AgftpOl",
        "outputId": "2881f5e7-c337-4153-e23c-02608098eabe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The Castle on the Sand\\n \\n\\n***TLDR: Kenneth Griffin and Citadel are running the single most profitable high-frequency market manipulation schemes in modern history. However, high-frequency trading comes with a significant number of risks that can cause flash crashes and general market failure. I also believe that Citadel has been executing a majority of its trades by using shares that it does not own, or by taking advantage of failures in the integrity of exchanges.***\\n\\n**PREFACE**\\n\\nSince the origination of the US stock exchange in 1792, countless investors have tried their hands at identifying profitable strategies for building their wealth. In the beginning, these strategies were relatively straightforward. First, find a business that you believe in. Next, take your own hard-earned money and extend a show of faith to the business that you believe will generate substantial returns. Then, after years of development and growth, reap the rewards of your faith through returns on your investment.\\n\\nI believe that, at their core, stock markets are fundamental to any economy. In its purest form, a stock market is a way for economies to establish healthy competition between corporations. It ensures financial liquidity and provides a necessary depressurization outlet for excess capital. In short, markets and exchanges provide the heartbeat of an economy.\\n\\nAt their worst, they are vehicles for manic speculation. They are Petri dishes for fraud that potentiate corporate greed and allow those who are already incredibly wealthy to inflate that wealth to hilarious levels. They are cold and emotionless; only serving as a vacuum for capital. In the end, the ticker takes over and becomes the business itself.\\n\\nI believe that there is one fund in particular that is single-handedly propping up the market through its manipulative options and short-selling strategies; ***Citadel LLC.*** Although I\\'m sure this doesn\\'t come as a surprise to many of those who frequent this subreddit, I\\'ll still include a **brief** synopsis below.\\n\\nIn 1990, a man named Kenneth Griffin founded Citadel LLC.\\n\\nFrom 2007-2008, Citadel barred investors from withdrawing money from their 7:1 levered accounts\\n\\nIn 2011, Citadel recruited energy traders from Enron the day after it collapsed\\n\\nIn 2021, Citadel and Point72 Capital invested $2.75 billion in Melvin Capital after their infamous 53% value collapse\\n\\nFrom 2014-2022, Citadel currently has 74 FINRA disclosures on file that detail a multitude of fraudulent trading activities.\\n\\n**SUMMARY**\\n\\nBelow is a clip from Citadel Securities LLC\\'s official FINRA BrokerCheck report showing the total number of regulatory filings against them.\\n\\n&amp;#x200B;\\n\\nhttps://preview.redd.it/bf3ltt3zx7ga1.png?width=1558&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=e5510b1a5ef8bfd435015e5a3ccfefb98b6bfdac\\n\\n&amp;#x200B;\\n\\nhttps://preview.redd.it/72ifzw71y7ga1.png?width=1302&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=379d19a81e0e2a91f45ba822f606da40fdc07ecd\\n\\nAbove is an example of the claim by NASDAQ MRX against Citadel for options manipulation. Specifically, the allegations pertain to [Rule 13c 3-5](https://www.sec.gov/divisions/marketreg/faq-15c-5-risk-management-controls-bd.htm) of the SEC\\'s Securities Exchange Act. It is important to note that almost all brokers/hedge funds have a few flags on their FINRA reports due to untimely filings, erroneous orders, or the like. However, Citadel has an ***Abnormally large number*** of these \"errors\".\\n\\nWhen confronted with these allegations, it is almost always easier to pay the $xxx,xxx fine rather than admit to any wrongdoing or go to court. To be exact, from 2010-present Citadel has paid over $60 million in fines alone from pre-trade manipulation claims by various markets. I will post the most significant injunction below.\\n\\n&amp;#x200B;\\n\\nhttps://preview.redd.it/cy68k7l2y7ga1.png?width=1161&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=08de8fa79944aa11032e98552ad83701efe114f6\\n\\nWhat this injunction suggests, is that Citadel knowingly manipulated market orders from their clearing service. These manipulations can include marking short orders as long orders, backdating trade dates to make it appear as though profits or losses were made during a certain period when they were not, or misrepresenting the types of securities sold.\\n\\n&amp;#x200B;\\n\\nhttps://preview.redd.it/j02sol37y7ga1.png?width=787&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=71f8c4751c441469ba17b5aaeb6993257f1d3a95\\n\\n80 million trades were misrepresented in SEC documentation\\n\\n&amp;#x200B;\\n\\nhttps://preview.redd.it/dsv8oz38y7ga1.png?width=827&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=104860afce30e8bbf98680741137af233826c884\\n\\nCited as \"undetected coding errors\"\\n\\nIf you are familiar with Bernie Madoff\\'s infamous Ponzi operation, these reports bear a striking resemblance to the SEC\\'s own findings in the year-long proceedings. However, I don\\'t believe that they\\'re operating in the exact same manner.\\n\\nCitadel is a pooled investment vehicle, which means they pool investor funds to purchase assets, securities, and commodities. Their SEC EDGAR 13F-HR reports do not necessarily raise any specific red flags, but it does raise some interesting questions.\\n\\n&amp;#x200B;\\n\\nhttps://preview.redd.it/whruo51x18ga1.png?width=977&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=5ccb05b6891a8763568f013251b52f47abbb4686\\n\\nIt is not uncommon for hedge funds to use manipulative options strategies, but the exception with Citadel is the sheer size and scale at which they can operate. Typically these manipulation techniques involve \"spoofing\" or placing large numbers of bid or ask orders and then canceling those orders prior to fulfillment. This artificially inflates or deflates stock prices and can manipulate spreads or supply/demand curves.\\n\\nLarge high-frequency trading firms can also front-run trades or place trades of their own in front of large trades they see coming through in their own dark pools. Again, this is not inherently *illegal* per se, but it does exemplify the informational inequality between institutional and retail traders. What crosses the line from \"technically legal\" to \"illegal\" with regard to Citadel\\'s operations is the blatant disregard for NBBO regulations that hold firms accountable for ensuring they have the shares to back their trades. ***In summary, Citadel most likely does not even own the large majority of the shares it is trading.*** These strategies have historically wreaked havoc in markets, and with the latest crash of the NYSE, it appears to be happening once again. At some point, exchanges simply can\\'t keep up with the volume of trades coming through at once in a fraction of a second.\\n\\n**So if this technique has been used for so long without issue, then why does it matter?**\\n\\nFundamentally speaking, the stock market operates on the assumption that issued shares by a company accurately reflect the laws of supply and demand. Whereas, a company that has solid fundamentals, growth, and revenue will be worth more than a company that is struggling to remain solvent. **Shareholder dilution** has been largely **ignored** over the past few years, and this is understandable as the number of dollars available to purchase shares has increased significantly. Just as the treasury can print a theoretically unlimited number of dollars, so too can companies print a theoretically unlimited number of shares.\\n\\nWe\\'ve become so used to share issuances, stock splits, and \"Fail to Deliver\" orders that we\\'ve completely lost sight of the inherent dangers of share dilution. Share dilution can be overlooked in markets that are flushed with capital, as the money must have more assets to chase. However, when markets begin to slow down, the supply of shares floating in the market becomes an exponentially compounding liability. We have companies with over 100% of their float being owned by institutions, and many have indirect ties to Citadel. For example, here is a recent SEC filing of Citadel Securities LLC.\\n\\n&amp;#x200B;\\n\\nhttps://preview.redd.it/ar99jwxby7ga1.png?width=1151&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=447451cf5f5e5fd9175a112fb9a06486dcc19f52\\n\\nhttps://preview.redd.it/euacawxby7ga1.png?width=1037&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9a5fa4d253e9f1fe812236eb12876308824bd78e\\n\\nhttps://preview.redd.it/e9iiswxby7ga1.png?width=1131&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=08808113637e16c9f7d0e4b640d4dc56547b944c\\n\\n&amp;#x200B;\\n\\nAs you can see, Citadel Advisors LLC is the original purchaser of the stock issuance followed by Kenneth Griffin\\'s own purchase. This specific stock\\'s float is already 101.6% held. This happens over and over again in Citadel\\'s filings.\\n\\n1st: Citadel subsidiaries purchase a large number of outstanding shares\\n\\n2nd: Kenneth Griffin purchases a large percentage of the class himself\\n\\n3rd: Kenneth Griffin offloads shares once the capital from Citadel subsidiaries has sufficiently spiked the price of the stock\\n\\nIt is a recurring cycle that may not necessarily be illegal but has incredibly devastating implications for the market. It also implies that Kenneth Griffin may be utilizing clients\\' capital through Citadel subsidiaries for personal gain.\\n\\n**THE VIX AND THE NASDAQ**\\n\\nI believe that the VIX is one of these complexes that has been heavily manipulated by HFT firms. I have written a post specifically regarding the VIX complex, so I won\\'t go into detail in this post. However, since VIX-related assets like UVXY, VXX, and UVIX are often used as insurance against market declines,  believe they are well-positioned to experience a large spike in activity if these high-frequency trading strategies fail or create a \"flash crash\" scenario. \\n\\nFurthermore, the VIX is currently sitting at 18.33, near its 52-week low of 17.06. If the suppression measures in place fail, regardless of market direction or sentiment, it could easily spike. It should be noted, however, that leveraged assets like UVXY often decay quickly. \\n\\nThe NASDAQ Exchange (NDAQ) is also in an impossible situation. In 2021 alone, there were over 1,000 new IPOs. The largest amount during a 1 year period in modern history. Many of these IPOs are at risk of being delisted due to exchange regulations. Recently, NDAQ has seen a rise in revenue from products and fees tied to listings and management expenses from this euphoric rise in IPO interest. However, I believe that as SPACs and \"zombie IPOs\" begin to fail, they will experience a sharp decline in associated revenue. As a matter of fact, they already are.\\n\\n&amp;#x200B;\\n\\n[NDAQ Working capital at an all-time low](https://preview.redd.it/qc0lsk1j18ga1.png?width=1200&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=79e335380204ea3e3b3c2b74c5d62ac1318e0090)\\n\\n**CONCLUSION**\\n\\nI understand that this is not an exhaustive report, and there are many other aspects of Citadel\\'s operations that need to be investigated by professionals before a conclusion can be made regarding its illicit operations. All I know is that history has shown over and over again that institutions that post record-breaking quarters during periods of significant economic decline or volatility are *most likely* doing so by manipulative or outright fraudulent activities. In the coming months, the damage done by manipulative high-frequency options and stock trading will become pronounced. I view the best general-interest methods of profiting during an event such as this to be PUTS on exchanges such as NDAQ or ICE and shares/CALLS of Vix-related assets.\\n\\nIt is only a matter of time before the cracks in the glass shatter entirely, and the world sees that Kenneth Griffin\\'s Citadel has been built on sand.\\n\\n***And the tide is coming in quickly.***'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# try one long sentence\n",
        "long_text_eg = df_sample['fulltext'][1]\n",
        "long_text_eg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "415\n",
            "481\n",
            "456\n"
          ]
        }
      ],
      "source": [
        "for c in chunks:\n",
        "    print(len(c.split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "aig71r06uLqB"
      },
      "outputs": [],
      "source": [
        "long_text_ls = long_text_eg.split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQRK80qOwg2_",
        "outputId": "0222d2ad-e16a-43c1-b7a5-3e0c45664f60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "116"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# many are meaningless whitespaces\n",
        "long_text_ls = [x.strip() for x in long_text_ls]\n",
        "len(long_text_ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs29gbz3w8dV",
        "outputId": "aac573ff-92d3-4b77-e778-da4dc94c5888"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# remove white spaces\n",
        "long_text_ls = [x for x in long_text_ls if x != '']\n",
        "len(long_text_ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# split inanother way\n",
        "ps = long_text_eg.split('\\n')\n",
        "ps = [p.strip() for p in ps]\n",
        "ps = [p for p in ps if p != \"\"]\n",
        "ps_token = [p.split() for p in ps]\n",
        "chunks = []\n",
        "current_chunk, current_length = '', 0\n",
        "for i in range(len(ps)):\n",
        "    p_len = len(ps_token[i]) + 1\n",
        "    if current_length + p_len < 500:\n",
        "        current_chunk += ps[i] + \"\\n\"\n",
        "        current_length += p_len\n",
        "    else:\n",
        "        chunks.append(current_chunk)\n",
        "        current_chunk, current_length = ps[i], p_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hzVRvCSouQiT"
      },
      "outputs": [],
      "source": [
        "# tokenized = tokenizer(long_text_ls, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "tokenized = tokenizer(chunks, padding=True, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "ds = Dataset.from_dict(tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "gD4CG1b6M-25"
      },
      "outputs": [],
      "source": [
        "dataloader = DataLoader(ds, batch_size=8, collate_fn=data_collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "outputs = []\n",
        "for batch in dataloader:\n",
        "    # print({k:v.shape for k,v in batch.items()})\n",
        "    logits = model(**batch).logits\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    outputs.append(probabilities.cpu().detach().numpy())\n",
        "final = np.concatenate(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'positive', 1: 'negative', 2: 'neutral'}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config.id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.01714356, 0.7390963 , 0.24376021]], dtype=float32)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final[final[:,2] < 0.5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test for short sentence\n",
        "short_text_ls = long_text_ls[:3]\n",
        "tokenized = tokenizer(short_text_ls, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "ds = Dataset.from_dict(tokenized)\n",
        "dataloader = DataLoader(ds, batch_size=8, collate_fn=data_collator)\n",
        "for batch in dataloader:\n",
        "    batch.keys()\n",
        "    break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_lines(text):\n",
        "    text_ls = text.split(\"\\n\")\n",
        "    text_ls = [x.strip() for x in text_ls]\n",
        "    text_ls = [x for x in text_ls if x != '']\n",
        "    return text_ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_paragraphs(long_text, limit = 500):\n",
        "    \"\"\"Split long texts into paragraphs. With upper limit of n tokens, do as few split as possible\n",
        "    \"\"\"\n",
        "    ps = long_text.split('\\n')\n",
        "    ps = [p.strip() for p in ps]\n",
        "    ps = [p for p in ps if p != \"\"]\n",
        "    ps_token = [p.split() for p in ps]\n",
        "    chunks = []\n",
        "    current_chunk, current_length = '', 0\n",
        "    for i in range(len(ps)):\n",
        "        p_len = len(ps_token[i]) + 1\n",
        "        if (current_length + p_len) < limit:\n",
        "            current_chunk += ps[i] + \"\\n\"\n",
        "            current_length += p_len\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk, current_length = ps[i], p_len\n",
        "    chunks.append(current_chunk.strip())\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pred_batch(dataloader):\n",
        "    \"\"\"Make prediction in batched way to prevent RAM overload\n",
        "    \"\"\"\n",
        "    outputs = []\n",
        "    for batch in dataloader:\n",
        "        with torch.no_grad():\n",
        "            logits = model(**batch).logits\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            outputs.append(probs)\n",
        "    return torch.cat(outputs, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to functions\n",
        "def pred_one_sentence(long_setence, filter=0.5):\n",
        "    text_ls = split_paragraphs(long_setence)\n",
        "    tokenized = tokenizer(text_ls, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    ds = Dataset.from_dict(tokenized)\n",
        "    dataloader = DataLoader(ds, batch_size=8, collate_fn=data_collator)\n",
        "    probs = pred_batch(dataloader)\n",
        "    # if filter is not None:\n",
        "    #     probs = probs[probs[:,2]<=filter]\n",
        "    return probs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "hide"
        ]
      },
      "source": [
        "# Predict Multiple Setences\n",
        "\n",
        "Strategy: \n",
        "- no parallelization: for each sentence, split, tokenize, turn to batches, predict\n",
        "- parallelization: split at first, keep id as itenfier, collectively turn to batches, predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fulltext</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10tottd</th>\n",
              "      <td>500k to invest in the most R way!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10tottd</th>\n",
              "      <td>I got 500k in various 401ks, Roths, and Broker...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10toqua</th>\n",
              "      <td>The Castle on the Sand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10toqua</th>\n",
              "      <td>***TLDR: Kenneth Griffin and Citadel are runni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10toqua</th>\n",
              "      <td>**PREFACE**</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  fulltext\n",
              "id                                                        \n",
              "10tottd                  500k to invest in the most R way!\n",
              "10tottd  I got 500k in various 401ks, Roths, and Broker...\n",
              "10toqua                             The Castle on the Sand\n",
              "10toqua  ***TLDR: Kenneth Griffin and Citadel are runni...\n",
              "10toqua                                        **PREFACE**"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_sample2 = df_sample.apply(split_lines,axis=1).explode('paragraph').set_index(\"id\",drop=True)\n",
        "df_sample2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized = tokenizer(df_sample2['paragraph'].to_list(), padding=True, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
              "    num_rows: 207\n",
              "})"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds = Dataset.from_dict(tokenized)\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataloader = DataLoader(ds, batch_size=8, collate_fn=data_collator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(207, 3)"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final = pred_batch(dataloader)\n",
        "final.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pred_multiple(df_input):\n",
        "    \"\"\"\n",
        "    arguments:\n",
        "    - df: a pandas dataframe of two columns: id and fulltext, each row is a reddit post\n",
        "    \"\"\"\n",
        "    # split post to paragraphs\n",
        "    df_split = df_input.apply(split_lines,axis=1).explode('paragraph').set_index(\"id\",drop=True)\n",
        "    # tokenize each paragraph\n",
        "    tokenized = tokenizer(df_split['paragraph'].to_list(), padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    # dict -> dataset -> dataloader\n",
        "    ds = Dataset.from_dict(tokenized)\n",
        "    dataloader = DataLoader(ds, batch_size=8, collate_fn=data_collator)\n",
        "    preds = pred_batch(dataloader)\n",
        "    # pred is in the same size as df_split\n",
        "    df_split[['positive','negative','neutral']] = preds\n",
        "    return df_split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0450, 0.0462, 0.9088],\n",
              "        [0.0171, 0.7391, 0.2438],\n",
              "        [0.0536, 0.1999, 0.7464]])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test function\n",
        "pred_one_sentence(long_text_eg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_list = []\n",
        "for folder in os.listdir(\"data\"):\n",
        "    data_file_path = os.path.join(\"data/\", folder, 'reddit.csv')\n",
        "    if os.path.isfile(data_file_path):\n",
        "        df = pd.read_csv(data_file_path)\n",
        "        df_list.append(df)\n",
        "df_total_raw = pd.concat(df_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 26731 entries, 0 to 5056\n",
            "Data columns (total 98 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   subreddit                      26731 non-null  object \n",
            " 1   selftext                       15000 non-null  object \n",
            " 2   author_fullname                26495 non-null  object \n",
            " 3   gilded                         26731 non-null  int64  \n",
            " 4   title                          26731 non-null  object \n",
            " 5   link_flair_richtext            26731 non-null  object \n",
            " 6   subreddit_name_prefixed        26731 non-null  object \n",
            " 7   hidden                         26731 non-null  bool   \n",
            " 8   pwls                           26730 non-null  float64\n",
            " 9   link_flair_css_class           18043 non-null  object \n",
            " 10  thumbnail_height               11604 non-null  float64\n",
            " 11  top_awarded_type               0 non-null      float64\n",
            " 12  hide_score                     26731 non-null  bool   \n",
            " 13  quarantine                     26731 non-null  bool   \n",
            " 14  link_flair_text_color          26665 non-null  object \n",
            " 15  upvote_ratio                   26731 non-null  float64\n",
            " 16  author_flair_background_color  364 non-null    object \n",
            " 17  total_awards_received          26731 non-null  int64  \n",
            " 18  media_embed                    26731 non-null  object \n",
            " 19  thumbnail_width                11604 non-null  float64\n",
            " 20  author_flair_template_id       368 non-null    object \n",
            " 21  is_original_content            26731 non-null  bool   \n",
            " 22  secure_media                   478 non-null    object \n",
            " 23  is_reddit_media_domain         26731 non-null  bool   \n",
            " 24  is_meta                        26731 non-null  bool   \n",
            " 25  category                       0 non-null      float64\n",
            " 26  secure_media_embed             26731 non-null  object \n",
            " 27  link_flair_text                21306 non-null  object \n",
            " 28  score                          26731 non-null  int64  \n",
            " 29  is_created_from_ads_ui         26731 non-null  bool   \n",
            " 30  author_premium                 26495 non-null  object \n",
            " 31  thumbnail                      26731 non-null  object \n",
            " 32  edited                         26731 non-null  bool   \n",
            " 33  author_flair_css_class         50 non-null     object \n",
            " 34  author_flair_richtext          26495 non-null  object \n",
            " 35  gildings                       26731 non-null  object \n",
            " 36  post_hint                      11956 non-null  object \n",
            " 37  content_categories             0 non-null      float64\n",
            " 38  is_self                        26731 non-null  bool   \n",
            " 39  subreddit_type                 26731 non-null  object \n",
            " 40  link_flair_type                26731 non-null  object \n",
            " 41  wls                            26730 non-null  float64\n",
            " 42  removed_by_category            13041 non-null  object \n",
            " 43  author_flair_type              26495 non-null  object \n",
            " 44  domain                         26495 non-null  object \n",
            " 45  allow_live_comments            26731 non-null  bool   \n",
            " 46  suggested_sort                 19709 non-null  object \n",
            " 47  url_overridden_by_dest         11314 non-null  object \n",
            " 48  view_count                     0 non-null      float64\n",
            " 49  archived                       26731 non-null  bool   \n",
            " 50  no_follow                      26731 non-null  bool   \n",
            " 51  is_crosspostable               26731 non-null  bool   \n",
            " 52  pinned                         26731 non-null  bool   \n",
            " 53  over_18                        26731 non-null  bool   \n",
            " 54  preview                        11956 non-null  object \n",
            " 55  all_awardings                  26731 non-null  object \n",
            " 56  awarders                       26731 non-null  object \n",
            " 57  media_only                     26731 non-null  bool   \n",
            " 58  link_flair_template_id         20941 non-null  object \n",
            " 59  can_gild                       26731 non-null  bool   \n",
            " 60  spoiler                        26731 non-null  bool   \n",
            " 61  locked                         26731 non-null  bool   \n",
            " 62  author_flair_text              762 non-null    object \n",
            " 63  treatment_tags                 26731 non-null  object \n",
            " 64  removed_by                     0 non-null      float64\n",
            " 65  distinguished                  0 non-null      float64\n",
            " 66  subreddit_id                   26731 non-null  object \n",
            " 67  link_flair_background_color    20765 non-null  object \n",
            " 68  id                             26731 non-null  object \n",
            " 69  is_robot_indexable             26731 non-null  bool   \n",
            " 70  author                         26731 non-null  object \n",
            " 71  discussion_type                39 non-null     object \n",
            " 72  num_comments                   26731 non-null  int64  \n",
            " 73  send_replies                   26731 non-null  bool   \n",
            " 74  whitelist_status               26730 non-null  object \n",
            " 75  contest_mode                   26731 non-null  bool   \n",
            " 76  author_patreon_flair           26495 non-null  object \n",
            " 77  author_flair_text_color        1022 non-null   object \n",
            " 78  permalink                      26731 non-null  object \n",
            " 79  parent_whitelist_status        26730 non-null  object \n",
            " 80  stickied                       26731 non-null  bool   \n",
            " 81  url                            26495 non-null  object \n",
            " 82  subreddit_subscribers          26731 non-null  int64  \n",
            " 83  created_utc                    26731 non-null  int64  \n",
            " 84  num_crossposts                 26731 non-null  int64  \n",
            " 85  media                          478 non-null    object \n",
            " 86  is_video                       26731 non-null  bool   \n",
            " 87  retrieved_utc                  26731 non-null  int64  \n",
            " 88  updated_utc                    26731 non-null  int64  \n",
            " 89  utc_datetime_str               26731 non-null  object \n",
            " 90  is_gallery                     1005 non-null   object \n",
            " 91  media_metadata                 1160 non-null   object \n",
            " 92  gallery_data                   497 non-null    object \n",
            " 93  poll_data                      5 non-null      object \n",
            " 94  crosspost_parent_list          134 non-null    object \n",
            " 95  crosspost_parent               134 non-null    object \n",
            " 96  author_cakeday                 69 non-null     object \n",
            " 97  edited_on                      18 non-null     float64\n",
            "dtypes: bool(24), float64(12), int64(9), object(53)\n",
            "memory usage: 15.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df_total_raw.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('2023-02-03 19:29:40', '2023-03-03 19:19:48')"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_total_raw['utc_datetime_str'].min(), df_total_raw['utc_datetime_str'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_total_raw.to_csv(\"data/reddit_all_dates.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 13855 entries, 0 to 5056\n",
            "Data columns (total 6 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   subreddit  13855 non-null  object\n",
            " 1   id         13855 non-null  object\n",
            " 2   title      13855 non-null  object\n",
            " 3   selftext   13855 non-null  object\n",
            " 4   post_id    13855 non-null  object\n",
            " 5   fulltext   13855 non-null  object\n",
            "dtypes: object(6)\n",
            "memory usage: 757.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df_total = df_total_raw[['subreddit','id','title','selftext']].copy()\n",
        "df_total['post_id'] = df_total['subreddit'] + \"_\" + df_total[\"id\"]\n",
        "# drop duplicates\n",
        "df_total = df_total.drop_duplicates(subset=['post_id'])\n",
        "# replace removed with empty string\n",
        "df_total['selftext'] = df_total['selftext'].str.replace(\"[removed]\",\"\")\n",
        "df_total = df_total.fillna(\"\")\n",
        "# filter empty posts\n",
        "cond = (df_total['title'] != \"\") | (df_total['selftext'] != \"\")\n",
        "df_total = df_total[cond]\n",
        "# create fulltext\n",
        "df_total['fulltext'] = df_total['title'] + \"\\n\" + df_total['selftext']\n",
        "df_total.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_total = df_total[['post_id','id','fulltext']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter\n",
        "df_filter = df_total[df_total['fulltext'].str.contains(\"|\".join(tickers))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12538, 3)"
            ]
          },
          "execution_count": 182,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_filter.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_one_sentence_vec = udf(lambda x: pred_one_sentence(x).tolist(), ArrayType(ArrayType(FloatType())))\n",
        "def sentiment_vectorizer(spark_df, large = False): \n",
        "    sentiment_df = spark_df.withColumn(\"vectors\", pred_one_sentence_vec(col(\"fulltext\")))\n",
        "    return sentiment_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "ss.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "ss = SparkSession.builder \\\n",
        "    .appName(\"MyApp\") \\\n",
        "    .config(\"spark.driver.memory\", \"14g\") \\\n",
        "    .config(\"spark.executor.memory\", \"14g\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'14g'"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "executor_memory = ss.sparkContext.getConf().get('spark.executor.memory')\n",
        "executor_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'http://localhost:4040'"
            ]
          },
          "execution_count": 171,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ss.sparkContext.uiWebUrl"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+--------------------+\n",
            "|     id|               title|            selftext|            fulltext|\n",
            "+-------+--------------------+--------------------+--------------------+\n",
            "|10tottd|500k to invest in...|I got 500k in var...|500k to invest in...|\n",
            "|10toqua|The Castle on the...| \\n\\n***TLDR: Ken...|The Castle on the...|\n",
            "+-------+--------------------+--------------------+--------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "df_sample_sp = ss.createDataFrame(df_sample[['id','title','selftext','fulltext']])\n",
        "df_sample_sp.show(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 5:>                                                          (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|     id|               title|            selftext|            fulltext|             vectors|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|10tottd|500k to invest in...|I got 500k in var...|500k to invest in...|[[0.20758328, 0.0...|\n",
            "|10toqua|The Castle on the...| \\n\\n***TLDR: Ken...|The Castle on the...|[[0.056986123, 0....|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "df_pred_toy = sentiment_vectorizer(df_sample_sp)\n",
        "df_pred_toy.show(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "df_pred_toy.write.format(\"json\").mode(\"overwrite\").option(\"header\",\"ture\").save(\"preds/reddit_toy.json\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Whole Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[post_id: string, id: string, fulltext: string]"
            ]
          },
          "execution_count": 183,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_total_sp = ss.createDataFrame(df_total)\n",
        "# df_total_sp.unpersist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-------+--------------------+\n",
            "|             post_id|     id|            fulltext|\n",
            "+--------------------+-------+--------------------+\n",
            "|wallstreetbets_11...|114bx75|Short MSFT? Chat ...|\n",
            "+--------------------+-------+--------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_filter_sp = ss.createDataFrame(df_filter)\n",
        "df_filter_sp.show(1)\n",
        "df_filter_sp = df_filter_sp.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "df_pred_sp = sentiment_vectorizer(df_filter_sp)\n",
        "df_pred_sp = df_pred_sp.cache()\n",
        "df_pred_sp.write.format(\"json\").mode(\"overwrite\").option(\"header\",\"ture\").save(\"preds/reddit_pred.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_preds = df_pred_sp.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12538 entries, 0 to 12537\n",
            "Data columns (total 4 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   post_id   12538 non-null  object\n",
            " 1   id        12538 non-null  object\n",
            " 2   fulltext  12538 non-null  object\n",
            " 3   vectors   12538 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 391.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df_preds.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_preds.to_csv(\"preds/reddit_pred.json/reddit_preds_vectors.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
